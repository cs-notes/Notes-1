\ifdefined\isphone
  \input{typeset_phone.tex}
\else
  \input{typeset_full.tex}
\fi

\begin{document}

% Info section

\title{CS 360 Term Notes}

\author{
    Craig, Shale\\
    \texttt{sakcraig@uwaterloo.ca}
}
\maketitle

% Note: uncomment these if I add them
\tableofcontents
% \listofAlgorithms
% \listoffigures

\chapter{Introduction}
    \section{Countable and Uncountable sets}
        When talking about the size of a set, they can be infinite or finite.
        When talking about an order, sets can be countable (i.e. enumerable) or
        uncountable (i.e. innumerable).

        Iff some set $A$ is enumerable, then there must exist an invertible
        function $f$ such that $f:\mathbbold{N} \to A$.
    \section{Alphabets, Strings, and Languages}
        Alphabets (usually denoted by $\Sigma$) are sets of unique characters.
        Strings are ordered sets of (possibly repeating characters in $\Sigma$).
        Languages are defined sets of words.

\chapter{Regular Languages}
    \section{Regular Languages}
        Regular Languages are languages recognizable by Regular Expressions.

        All finite languages are regular. Not all regular languages are finite.
    \section{State Machines}
        \subsection{DFAs} % (fold)
            DFA is short for Deterministic Finite State Machine.

            A DFA $A$ is a $5$-tuple of $\tuple{Q, \Sigma, \delta, q_0, F}$.
            Where $Q$ is a set of possible states, $\Sigma$ is the language,
            $\delta$ is a transfer function $\delta: Q, \Sigma \to Q$.
        \subsection{NFAs} % (fold)
            DFA is short for Non-deterministic Finite State Machine.

            A NFA $A$ is a $5$-tuple of $\tuple{Q, \Sigma, \delta, q_0, F}$.
            Where $Q$ is a set of possible states, $\Sigma$ is the language,
            $\delta$ is a transfer function $\delta: Q, \Sigma \to P(Q)$. $P(Q)$
            is the powerset of $Q$ (i.e. the set of all subsets of $Q$).

    \section{Equivalence of NFAs and DFAs}
        NFAs and DFAs are equivalent.

        We can change an DFA into a NFA trivially.

        We can change a NFA into a DFA through the powerset construction - i.e.
        we can define $\delta_{DFA}$ by calling each $R \in P(Q_{NFA})$ a state
        of our new NFA. Transition functions will be $R, \Sigma \to Q_{DFA}$.

    \section{Regular Operations}
        Given two languages $A$ and $B$, there are three regular operations:
        \begin{enumerate}
            \item $C = A \cup B$:

                $C$ is defined to be the language that accepts any string in $A$
                or $B$ or both.

            \item $C = A \cap B$:

                $C$ is defined to be the language that accepts any string in
                both $A$ \uline{and} $B$.

            \item $C = A^*$:

                $C$ is defined to be the language that accepts any string in
                $\{ \varepsilon \} \cup A \cup AA \cup AAA \cup \ldots$

                $\varepsilon$ is the empty string.
        \end{enumerate}
    \section{Closure Properties of Regular Languages}
        Given that $A$ and $B$ are regular:
        \begin{enumerate}
             \item $A \cup B$ is regular
             \item $A \cap B$ is regular
             \item $A^*$ is regular
         \end{enumerate}
    \section{Regular Expressions and Their Equivalence with NFAs and DFAs}
        Regular expressions describe the same languages as NFAs/DFAs:

        Regular expressions can be turned into NFA's trivially. NFAs can
        describe the same languages as DFAs, so that reduction works.

        Transitions in DFAs can be reduced to Regular Expressions by forcing
        transitions to have Regular Expressions, then removing state diagrams
        until a Regular Expression appears.
    \section{Techniques for Proving Certain Languages are Non-Regular}
        We can use a few techniques to prove certain languages are non-regular,
        but the main one seems to be that the pumping lemma holds for every
        regular language.

        The \uline{pumping lemma for Regular languages} states:

        For every a Regular Language $L$, there is a $p \ge 1$ such that every
        $w \in L$ where $|w| \ge p$ can be written as $w = xyz$. Where the
        following holds:
        \begin{itemize}
            \item $|y| \ge 1$
            \item $|xy| \le p$
            \item for all $i \ge 0$, $xy^iz \in L$
        \end{itemize}
        i.e. every Regular Language $L$ has a pumping length $p$ such that every
        string $w$ where $|w|\ge p$ must have a portion that can be repeated
        indefinitely (or removed altogether).

    \section{Further Discussion of Regular Languages, Finite Automata, and Regular Expressions}
        TODO: Not sure what we did here.

\chapter{Context-Free Grammars and Languages}
    \section{Context-Free Grammars and Languages}
        A context-free grammar $G$ defines a context-free language $L(G)$.

        CFG's are defined as a 4-tuple $G = (V, \Sigma, R, S)$, where:
        \begin{itemize}
            \item $V$ is a finite set of non-terminal characters.
            \item $\Sigma$ is a set of terminal characters that make up the
            language. As a rule, $V \cap \Sigma = \varnothing$.
            \item $R$ is a relation $R: V \to (V \cup \Sigma)^*$.
            \item $S$ is the start variable (or start symbol. By definition,
            $S \in V$.
        \end{itemize}

        For example, this is a context-free grammar that accepts all strings
        that are odd length and contain a $1$ in the middle:
        \begin{align*}
            S &\to USU | 1 \\
            U &\to 0 | 1 \\
        \end{align*}

        Every regular language can be expressed by a CFG.
    \section{Parse Trees and Ambiguity}
        Parse trees are simple, and they are ambiguous.

        For example, how many ways are there to parse \verb|x+++x|?
        It's probably defined in the language spec, but a CFG may mess up
        interpreting this line of code.

    \section{More Examples of Context-Free Grammars}
        I can't believe we spent a full class on this. It's simple.

    \section{Normal forms for CFGs}
        \href{http://en.wikipedia.org/wiki/Chomsky_normal_form}{Chomsky Normal Form}
        is a form of writing CFGs. All CFGs can be written in CNF.

        A grammar is said to be in CNF if all production rules are in the form:
        \begin{align*}
            A &\to BC \\
            A &\to \alpha \\
            A &\to \varepsilon
        \end{align*}
        Where $B$ and $C$ are nonterminal symbols, are not $S$, $\alpha$ is a
        terminal symbol. Of course, $\varepsilon$ is the empty string.
    \section{Closure Properties for CFLs}
        Context-Free Languages are closed under the following operations:
        (Assume that $A$, $B$ are in CFL)
        \begin{enumerate}
            \item $A \cup B$
            \item $AB$
            \item $\text{reverse}(A)$
            \item $A^*$
        \end{enumerate}
        $\mathsf{A}$, $A \cap B$, $A \setminus B$ are not CFLs.

    \section{Techniques for Proving Certain Languages are Non-Context-Free}
        We can use a few techniques to prove certain languages are
        non-Context-Free, but the main one is the pumping lemma holds for every
        Context-Free language.

        The \uline{pumping lemma for Context-Free languages} states:

        For every a Context-Free Language $L$, there exists a $p \ge 1$ such
        that for every $w \in L$ where $|w| \ge p$ can be written as
        $w = uvxyz$.
        Where the following holds:
        \begin{itemize}
            \item $|vxy| \le p$
            \item $vx \ne \varepsilon$
            \item For all $i \ge 0$, $uv^ixy^iz \in L$.
        \end{itemize}
        i.e. every Context-Free Language $L$ has a pumping length $p$ such that
        every string $w$ where $|w| \ge p$ must have a rule (or chain of rules)
        such that
        indefinitely (or removed altogether).
    \section{Further Discussion of Context-Free Languages and Grammars}
        TODO: Not sure what we did here.

\chapter{Turing Machines}
    \section{Pushdown Automata}
        A machine that has a stack and reads input from a tape. It can recognize
        a superset of Context-Free Languages.

        A Pushdown Automata can be expressed as a 7-tuple:
        \begin{align*}
            M = \tuple{Q, \Sigma, \Gamma, \delta, q_0, Z, F}
        \end{align*}
        Where:
        \begin{itemize}
            \item $Q$ is a finite set of states.
            \item $\Sigma$ is the alphabet.
            \item $\Gamma$ is the stack alphabet. It's the set of symbols that
            can go on the stack.
            \item $q_0 \in Q$ is the start state.
            \item $Z \in \Gamma$ is the initial stack symbol. It's the initial
            value in the stack.
            \item $F \subseteq Q$ is the set of accepting states.
            \item $\delta$ is the transition function that operates as follows:
            \begin{itemize}
                \item Pop $\alpha \in \Gamma$ from the stack.
                \item Read input $r \in (\Sigma \cup \{ \varepsilon \})$.
                \item See current state is $q \in Q$.
                \item Move to a new state $q' \in Q$.
                \item Push a new variable on the stack: $\alpha' \in \Gamma$.
            \end{itemize}
            i.e. $\delta: \Gamma \times (\Sigma \cup \{ \varepsilon \}) \times Q \to Q \times \Gamma^*$
        \end{itemize}
    \section{The Turing machine model}
        Turing Machines are similar to PDAs but aren't exactly the same thing.
        Turing-machines consist of an infinitely long tape, a tape head, a state
        register and a function.

        More formally, Turing Machines can be specified by a 7-Tuple:
        \begin{align*}
            M = \tuple{Q, \Gamma, b, \Sigma, \delta, q_0, F}
        \end{align*}
        Where:
        \begin{enumerate}
            \item $Q$ is a set of states
            \item $\Gamma$ is the tape alphabet. Basically what the tape can
            store.
            \item $b \in \Gamma$ is the blank symbol. It's the ``initial'' value
            of most of the tape.
            \item $\Sigma \in \Gamma$ is the set of input symbols.
            \item $F \subseteq Q$ is the set of accepting states.
            \item $\delta: Q \setminus F \times \Gamma \to Q \times \Gamma \times \{ L, R \}$.
                $\delta$ is the transition function. It changes the state,
                writes to the tape, and moves the tape based on based on the
                value of the tape at the current location and starting state.
        \end{enumerate}
    \section{Variants of Turing Machines}
        TODO: Not sure what we did here.
    \section{Specifications of DTMs}
        TODO: Not sure what we did here.
    \section{The Church-Turing thesis}
        Basically, the thesis states that a function is algorithmically
        computable if and only if it is computable by a Turing machine.
    \section{Encoding schemes}
        We can encode anything as a set of 0's and 1's by serializing it. For
        example, we can denote an encoding of a DTM $M$ as $\tuple{M}$.

        That's all I believe I need to write.

\chapter{Decidable and Recognizable Languages}
    \section{Decidable and Turing-Recognizable Languages}
        Turing-Recognizable Languages are languages that can be ``recognized''
        by a Turing Machine. i.e. A language $P$ is said to be Turing
        Recognizable if there exists a Turing Machine $M$ such that $L(M) = P$.

        Decidable Languages are languages that can be ``decided'' by a Turing
        Machine. i.e. A language $P$ is said to be decidable if there exists a
        Turing Machine $M$ such that for every input string $r \in \Sigma^*$,
        $M$ will halt and output ``accept'' or ``reject''.

    \section{Closure Properties of Decidable and Turing-Recognizable Languages}
        Decidable Languages are closed under:
        \begin{itemize}
            \item Union
            \item Intersection
            \item Complementation
            \item Concatenation
            \item Kleene Star
        \end{itemize}

        Turing-Recognizable Languages are closed under:
        \begin{itemize}
            \item Union
            \item Intersection
            \item Concatenation
            \item Kleene Star
        \end{itemize}
    \section{Some Decidable Languages}
        \begin{itemize}
            \item $A_{DFA} = \{ \tuple{B, w} | B \text{is a DFA that accepts input string w} \}$
            \item $A_{NFA} = \{ \tuple{B, w} | B \text{is an NFA that accepts input string w} \}$
            \item $A_{REX} = \{ \tuple{B, w} | B \text{is a regular expression that accepts input string w} \}$
            \item $E_{DFA} = \{ \tuple{A} | A \text{is a DFA and } L(A) = \emptyset \}$
            \item $EQ_{DFA} = \{ \tuple{A, B} | A \text{ and } B \text{are DFAs and } L(A) = L(B) \}$
            \item $A_{CFG} = \{ \tuple{G, w} | G \text{ is a CFG that generates } w \}$
            \item $A_{CFG} = \{ \tuple{G, w} | G \text{ is a CFG that generates } w \}$
            \item $E_{CFG} = \{ \tuple{G} | G \text{ is a CFG and } L(G) = \emptyset \}$
            \item $EQ_{CFG} = \{ \tuple{G, H} | G \text{ and } H \text{are DFAs and } L(G) = L(H) \}$
            \item Every context-free language is decidable.
        \end{itemize}
    \section{A Non-Turing-Recognizable Language}
        TODO: In this portion, I believe that we did the Halting Problem. Need
        to verify.
    \section{Undecidability of the Halting Problem}
        \uline{Description:}
        Given a description of an arbitrary computer program, decide whether the
        program finishes running or continues forever.
        In other words, given a program and an input, please decide if the
        program eventually halts when run with that input? (or will it run
        forever)

        \uline{Proof of undecidability:}
        Suppose a solution to the halting problem $H$ ``accepts'' input
        $H(P, I)$ if and only if $P$ halts on $I$. Otherwise, it will always
        ``reject''.

        Now we define the code $Z$ as follows:
        \begin{verbatim}
            Program(String x):
                if Halt(x, x):
                    Loop forever
                else:
                    Halt
        \end{verbatim}
        This is a pretty simple program, but if we run $Z$ with input $Z$, we
        have impossible conclusions:
        \begin{itemize}
            \item In the case that $Halt(Z,Z)$ is true, we will loop forever.
            This is a contradiction.
            \item In the case that $Halt(Z,Z)$ is false, we will halt. This is a
            contradiction.
        \end{itemize}
        This function $H$ cannot exist.
    \section{Reductions}
        One of the easiest ways to prove something is not decidable or
        not Turing-Recognizable is to establish a mapping from some other
        language you already know to be undecidable or not to be
        Turing-Recognizable.

        We can define $\le_m$ reductions (i.e. mapping reductions) as follows:

        Being able to reduce problem $A$ to $B$ by using a mapping reducibility
        means that a computable function $f$ exists that converts instances of
        $A$ to $B$. If we have this $f$ (called a reduction), we can solve $A$
        with a solver for $B$.

        We want to find a way to ``translate'' every problem in $A$ to a problem
        in $B$.

        By finding $A \le_m B$ and knowing some things about $A$, we know some
        things about $B$:
        \begin{itemize}
            \item $A \le_m B$ and $A$ is not decidable, then $B$ is not
            decidable.
            \item $A \le_m B$ and $A$ is not Turing-Recognizable, then $B$ is
            not Turing-Recognizable.
        \end{itemize}
    \section{More Undecidable and Non-Turing-Recognizable Languages}
        TODO: Not sure what we did here.
    \section{Further Discussion of Turing Machines}
        TODO: Not sure what we did here.

\chapter{Computation Time}
    \section{Time-Bounded Computation}
        TODO: Complete Me
    \section{The Time Hierarchy Theorem}
        I'm relatively sure it goes as follows:
        \begin{align*}
            \mbox{P} \subseteq \mbox{NP} \subseteq \mbox{EXPTIME}
        \end{align*}
        TODO: Complete Me
    \section{Boolean Circuits and Their Relationship to Turing Machines}
        Any Turing Machine can be simulated by a boolean circuit, and every
        boolean circuit can be simulated by a Turing Machine.
    \section{P and EXP}
        $P$ is the class of decision problems which can be solved by a DTM using
        a polynomial amount of computation time. i.e. Polytime or $P$ time.

        $EXP$ is the set of all decision problems solvable by a DTM in
        $O(2^{p(n)})$ time, where $p(n)$ is a polynomial function of $n$.

    \section{Nondeterministic Turing Machines}
        Nondeterministic Turing Machines (NDTMs) are defined as a 6-tuple:
        \begin{align*}
            M = (Q, \Sigma, \iota, \sqcup, A, \delta)
        \end{align*}
        Where:
        \begin{itemize}
            \item $Q$ is a finite set of states.
            \item $\Sigma$ is a finite set of symbols (the tape alphabet).
            \item $\iota \in Q$ is the initial state.
            \item $\sqcup \in \Sigma$ is the blank symbol.
            \item $A \subseteq Q$ is the set of accepting states.
            \item $\delta$ is the transfer function
            $Q \setminus A \times \Sigma \to Q \times \Sigma \times \{ L, R \}$
        \end{itemize}
        The difference between a NDTM (NTM?) and a DTM is that NDTMs inhabit a
        set of states instead of a single state. They accept the state if any of
        their current states are accepted.

    \section{NP}
        We say that $NP$ is the set of problems that are defined as follows:
        \begin{align*}
            \mbox{NP} &= \bigcup_{k \in \mathbbold{N}} \mbox{NTIME}(n^k)
        \end{align*}
        Alternatively, we can define \uline{NP} using DTMs. A language $L$ is in
        NP if and only if there exist polynomials $p$ and $q$ and a DTM $M$ such
        that:
        [We call $M$ a TODO what do we call $M$?]
        \begin{itemize}
            \item For all $x$ and $y$, the machine $M$ runs in time $p(|x|)$ on
            input $\tuple{x, y}$.
            \item For all $x$ in $L$, there exists a string $y$ of length
            $q(|x|)$, $M$ accepts $\tuple{x, y}$.
            \item For all $x$ not in $L$, there exists a string $y$ of length
            $q(|x|)$, $M$ rejects $\tuple{x, y}$.
        \end{itemize}
        We can say that a language $L$ is NP-Complete if $L$ is NP and every $A$
        in NP is polynomial time reducible to $B$.

    \section{Polynomial-Time Mapping Reductions}
        Language $A$ is polynomial time mapping reducible (or simply polytime
        reducible) to $B$, written $A \le_p B$ if a polytime computable function
        $f : \Sigma^* \to \Sigma^*$ exists such that for every $w$,
        $w \in A \leftrightarrow f(w) \in B$.

        If $A \le_p B$ and $B \in P$, then $A \in P$.

        $\mbox{3SAT}$ is polytime reducible to $\mbox{CLIQUE}$. This means that
        if $\mbox{CLIQUE}$ is solvable in polynomial time, so is $\mbox{3SAT}$.

        Set of related notes:
        \begin{itemize}
            \item If $B$ is NP-Complete and $B \in P$, then P = NP
            \item If $B$ is NP-Complete and $B \le_p C$ for $C$ in NP, then $C$
            is NP-Complete.
            \item 3SAT, CLIQUE, SAT, Vertex Cover, HamPath, Subset-SUM are all
            NP-Complete.
        \end{itemize}

    \section{The Cook-Levin Theorem}
        The Cook-Levin theorem states that boolean satisfiability is
        NP-Complete.

        That is, any problem in NP can be reduced to boolean satisfiability in
        polynomial time by a deterministic Turing Machine to the problem of
        determining whether a Boolean formula is satisfiable.
    \section{Further Discussion of Computability and Complexity theory}
\end{document}